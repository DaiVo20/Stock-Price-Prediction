{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd05d97ad4eda96f4e0dcd5ae4f97368654619500468c6147550d2a1b2a1881f9a5",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "5d97ad4eda96f4e0dcd5ae4f97368654619500468c6147550d2a1b2a1881f9a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "## Loading of dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_default = \"./data/stock_data.csv\"\n",
    "stock_data = pd.read_csv(path_default)\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = stock_data['Stock'].unique()\n",
    "print(companies)"
   ]
  },
  {
   "source": [
    "## Split training and test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks ={}\n",
    "for i in companies:\n",
    "  stocks[i] = stock_data[stock_data['Stock'] == i][[\"Date\", \"Close\"]]\n",
    "  print(stocks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(data, date):\n",
    "\n",
    "  close_train = data['Close'][data['Date'] < date].to_numpy()\n",
    "  data_train = []\n",
    "  X_train = [] \n",
    "  Y_train = []\n",
    "  for i in range(0, len(close_train), 5):\n",
    "    try:\n",
    "      data_train.append(close_train[i : i + 5])\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  if len(data_train[-1]) < 5:\n",
    "    data_train.pop(-1)\n",
    "  \n",
    "  X_train = data_train[0 : -1]\n",
    "  X_train = np.array(X_train)\n",
    "  X_train = X_train.reshape((-1, 5, 1))\n",
    "  Y_train = data_train[1 : len(data_train)]\n",
    "  Y_train = np.array(Y_train)\n",
    "  Y_train = Y_train.reshape((-1, 5, 1))\n",
    "\n",
    "  close_test = data['Close'][data['Date'] >= date].to_numpy()\n",
    "  data_test = []\n",
    "  X_test = []\n",
    "  Y_test = []\n",
    "  for i in range(0, len(close_test), 5):\n",
    "    try:\n",
    "      data_test.append(close_test[i : i + 5])\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  if len(data_test[-1]) < 5:\n",
    "    data_test.pop(-1)\n",
    "  \n",
    "  X_test = data_test[0 : -1]\n",
    "  X_test = np.array(X_test)\n",
    "  X_test = X_test.reshape((-1, 5, 1))\n",
    "  Y_test = data_test[1 : len(data_test)]\n",
    "  Y_test = np.array(Y_test)\n",
    "  Y_test = Y_test.reshape((-1, 5, 1))\n",
    "\n",
    "  return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "source": [
    "## Create model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "                                      tf.keras.layers.LSTM(200, input_shape = (5, 1), activation = tf.nn.leaky_relu, return_sequences = True),\n",
    "                                      tf.keras.layers.LSTM(200, activation = tf.nn.leaky_relu),\n",
    "                                      tf.keras.layers.Dense(200, activation = tf.nn.leaky_relu),\n",
    "                                      tf.keras.layers.Dense(100, activation = tf.nn.leaky_relu),\n",
    "                                      tf.keras.layers.Dense(50, activation = tf.nn.leaky_relu),\n",
    "                                      tf.keras.layers.Dense(5, activation = tf.nn.leaky_relu)\n",
    "                                      ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Custom Learning Rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "  \n",
    "  if epoch <= 150:\n",
    "    lrate = (10 ** -5) * (epoch / 150) \n",
    "  elif epoch <= 400:\n",
    "    initial_lrate = (10 ** -5)\n",
    "    k = 0.01\n",
    "    lrate = initial_lrate * math.exp(-k * (epoch - 150))\n",
    "  else:\n",
    "    lrate = (10 ** -6)\n",
    "  \n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1, 1001, 1)]\n",
    "lrate = [scheduler(i) for i in range(1, 1001, 1)]\n",
    "plt.plot(epochs, lrate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "source": [
    "## Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Apple model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mark = '2017-01-01'\n",
    "AAPL_X_train,AAPL_Y_train,AAPL_X_test,AAPL_Y_test=SplitData(stocks['AAPL'], date_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_Model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AAPL_hist = AAPL_Model.fit(AAPL_X_train, AAPL_Y_train, epochs = 1000, validation_data = (AAPL_X_test, AAPL_Y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = AAPL_hist.history\n",
    "\n",
    "loss = history_dict[\"loss\"]\n",
    "root_mean_squared_error = history_dict[\"root_mean_squared_error\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "val_root_mean_squared_error = history_dict[\"val_root_mean_squared_error\"]\n",
    "\n",
    "epochs = range(1, len(loss) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "ax1.plot(epochs, loss, label = 'Training Loss')\n",
    "ax1.plot(epochs, val_loss, label = 'Validation Loss')\n",
    "ax1.set(xlabel = \"Epochs\", ylabel = \"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, root_mean_squared_error, label = \"Training Root Mean Squared Error\")\n",
    "ax2.plot(epochs, val_root_mean_squared_error, label = \"Validation Root Mean Squared Error\")\n",
    "ax2.set(xlabel = \"Epochs\", ylabel = \"Loss\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Predicting the closing stock price of Apple"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_prediction = AAPL_Model.predict(AAPL_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(stock_data['AAPL']['Date'][stock_data['AAPL']['Date'] < date_mark], \n",
    "        stock_data['AAPL']['Close'][stock_data['AAPL']['Date'] < date_mark], label = 'Training')\n",
    "\n",
    "plt.plot(stock_data['AAPL']['Date'][stock_data['AAPL']['Date'] >= date_mark], \n",
    "        stock_data['AAPL']['Close'][stock_data['AAPL']['Date'] >= date_mark], label = 'Testing')\n",
    "\n",
    "plt.plot(stock_data['AAPL']['Date'][stock_data['AAPL']['Date'] >= date_mark], \n",
    "        AAPL_prediction.reshape(-1), label = 'Predictions')\n",
    "        \n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt(mean_squared_error(AAPL_Y_test.reshape(-1, 5), AAPL_prediction))\n",
    "mape = np.mean(np.abs(AAPL_prediction - AAPL_Y_test.reshape(-1, 5))/np.abs(AAPL_Y_test.reshape(-1, 5)))\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAPE: {mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}